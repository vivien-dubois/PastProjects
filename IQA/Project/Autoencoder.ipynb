{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of the autoencoders using the IQA metrics\n",
    "\n",
    "### Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numbers\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import models\n",
    "import importlib\n",
    "\n",
    "importlib.reload(utils)\n",
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid_loc = \"../tid2013\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_tid = utils.read_scores(\"{0}/mos.txt\".format(tid_loc)).astype(np.float32)\n",
    "ref_images = utils.read_images(\"{0}/reference_images\".format(tid_loc))\n",
    "ref_images = ref_images.astype(np.float32)\n",
    "\n",
    "def key_fun(x):\n",
    "    splitted = x.split(\"_\")\n",
    "    return 10000 * int(splitted[0][1:]) + 100 * int(splitted[1]) + int(splitted[2][:-4])\n",
    "image_names_tid = sorted(os.listdir(\"{0}/distorted_images\".format(tid_loc)), key=key_fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Due to the way Tensorflow works these two cells need to be run when training a new\n",
    "# autoencoder. If the training step method are not redefined for the new generator exception\n",
    "# will be thrown.\n",
    "generator = make_generator()\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "generator_loss = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_tensor = tf.convert_to_tensor(ref_images, tf.float32)\n",
    "@tf.function\n",
    "def gen_train_step_r(metric, _lambda=1):\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        generated_images = generator(tf.convert_to_tensor(ref_images, tf.float32))\n",
    "        in_list = []\n",
    "        in_list_ref = []\n",
    "        for j in range(64):\n",
    "            ul1 = np.random.randint(384-32)\n",
    "            ul2 = np.random.randint(512-32)\n",
    "            new_in = generated_images[:, ul1:ul1+32, ul2:ul2+32, :]\n",
    "            in_list.append(new_in)\n",
    "            new_in_ref = ref_tensor[:, ul1:ul1+32, ul2:ul2+32, :]\n",
    "            in_list_ref.append(new_in_ref)\n",
    "\n",
    "        input_tensor = tf.stack(in_list, 1)\n",
    "        input_tensor_ref = tf.stack(in_list_ref, 1)\n",
    "        scores_output = metric([tf.cast(input_tensor, tf.float32), tf.cast(input_tensor_ref, tf.float32)])\n",
    "        gen_loss = -tf.math.reduce_mean(scores_output) + _lambda * generator_loss(generated_images, ref_images.astype(np.float32))\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_weights)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_weights))\n",
    "\n",
    "@tf.function\n",
    "def gen_train_step_error():\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        generated_images = generator(tf.convert_to_tensor(ref_images, tf.float32))\n",
    "        gen_loss = generator_loss(generated_images, ref_images.astype(np.float32))\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_weights)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_weights))\n",
    "\n",
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def gen_train_step(metrics, _lambda=1):\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        generated_images = generator(tf.convert_to_tensor(ref_images))\n",
    "        patches_gen = tf.image.extract_patches(generated_images, [1,32,32,1], [1,32,32,1], [1,1,1,1], 'SAME')\n",
    "        patches_gen = tf.reshape(patches_gen, (25, 192, 32, 32, 3))\n",
    "        patches_ref = tf.image.extract_patches(ref_images, [1,32,32,1], [1,32,32,1], [1,1,1,1], 'SAME')\n",
    "        patches_ref = tf.reshape(patches_ref, (25, 192, 32, 32, 3))\n",
    "        #patches_gen, patches_ref = extract_random_patches(generated_images, ref_images, 192, 32)\n",
    "        scores_output = metrics[0]([tf.cast(patches_gen, tf.float32), tf.cast(patches_ref, tf.float32)])\n",
    "        for i in range(len(metrics) - 1):\n",
    "            scores_output += metrics[i+1]([tf.cast(patches_gen, tf.float32), tf.cast(patches_ref, tf.float32)])\n",
    "        scores_output /= len(metrics)\n",
    "        gen_loss = -tf.math.reduce_mean(scores_output) + _lambda * generator_loss(generated_images, ref_images.astype(np.float32))\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_weights)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_weights))\n",
    "\n",
    "@tf.function\n",
    "def gen_train_step_full(metrics, _lambda=1):\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        generated_images = generator(tf.convert_to_tensor(ref_images, tf.float32))\n",
    "        scores_output = metrics[0]([tf.cast(generated_images, tf.float32), tf.cast(ref_images, tf.float32)])\n",
    "        for i in range(len(metrics) - 1):\n",
    "            scores_output += metrics[i+1]([tf.cast(generated_images, tf.float32), tf.cast(ref_images, tf.float32)])\n",
    "        scores_output /= len(metrics)\n",
    "        gen_loss = -tf.math.reduce_mean(scores_output) + _lambda * generator_loss(generated_images, ref_images.astype(np.float32))\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_weights)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_weights))\n",
    "\n",
    "@tf.function\n",
    "def gen_train_step_metric(metrics):\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        generated_images = generator(tf.convert_to_tensor(ref_images))\n",
    "        patches_gen = tf.image.extract_patches(generated_images, [1,32,32,1], [1,32,32,1], [1,1,1,1], 'SAME')\n",
    "        patches_gen = tf.reshape(patches_gen, (25, 192, 32, 32, 3))\n",
    "        patches_ref = tf.image.extract_patches(ref_images, [1,32,32,1], [1,32,32,1], [1,1,1,1], 'SAME')\n",
    "        patches_ref = tf.reshape(patches_ref, (25, 192, 32, 32, 3))\n",
    "        #patches_gen, patches_ref = extract_random_patches(generated_images, ref_images, 192, 32)\n",
    "        scores_output = metrics[0]([tf.cast(patches_gen, tf.float32), tf.cast(patches_ref, tf.float32)])\n",
    "        for i in range(len(metrics) - 1):\n",
    "            scores_output += metrics[i+1]([tf.cast(patches_gen, tf.float32), tf.cast(patches_ref, tf.float32)])\n",
    "        scores_output /= len(metrics)\n",
    "        gen_loss = -tf.math.reduce_mean(scores_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_weights)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid patches\n",
    "\n",
    "The number of iterations used in the following cells is too small to reach convergence, this is to demonstrate the way the code works not to obtain results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for grid patches using loss L = -IQA and a WaDIQaM model with sigmoid\n",
    "model = tf.keras.models.load_model(\"saved_weights/metric_wadiqam.h5\")\n",
    "for i in range(500):\n",
    "    if i % 50 == 0:\n",
    "        print(\"Iteration: \" + str(i))\n",
    "    gen_train_step_metric([model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for grid patches using loss L = lambda * MSE - IQA and a WaDIQaM model with sigmoid\n",
    "model = tf.keras.models.load_model(\"saved_weights/metric_wadiqam.h5\")\n",
    "l = np.float32(0.01)\n",
    "for i in range(1000):\n",
    "    if i % 500 == 0:\n",
    "        print(\"Iteration: \" + str(i))\n",
    "    gen_train_step_full([model], l)\n",
    "\n",
    "predictions = generator(ref_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = utils.tid_batch_generator(tid_loc, ref_images_tid, scores_tid, image_names_tid, False, full_images=True)\n",
    "counter = 0\n",
    "i = 0\n",
    "model = models.get_wadiqam_model()\n",
    "model.load_weights(\"saved_weights/wadiqam.hdf5\")\n",
    "while i < 3000:\n",
    "    im, score = next(gen)\n",
    "    dist_tensor = tf.convert_to_tensor(np.reshape(im[\"x\"], (1, 384, 512, 3)))\n",
    "    ref_tensor = tf.convert_to_tensor(np.reshape(im[\"y\"], (1, 384, 512, 3)))\n",
    "    patches_gen = tf.image.extract_patches(dist_tensor, [1,32,32,1], [1,32,32,1], [1,1,1,1], 'SAME')\n",
    "    patches_gen = tf.reshape(patches_gen, (1, 192, 32, 32, 3))\n",
    "    patches_ref = tf.image.extract_patches(ref_tensor, [1,32,32,1], [1,32,32,1], [1,1,1,1], 'SAME')\n",
    "    patches_ref = tf.reshape(patches_ref, (1, 192, 32, 32, 3))\n",
    "    cont = True\n",
    "    while cont:\n",
    "        # Perform gradient ascent on the distorted images until the score has improved enough\n",
    "        clear_output(wait=True)\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            gen_tape.watch(dist_tensor)\n",
    "            scores_output = model([tf.cast(patches_gen, tf.float32), tf.cast(patches_ref, tf.float32)])\n",
    "            print(scores_output)\n",
    "            print(\"{0}: {1}\".format(i, np.mean(scores_output)))\n",
    "            if np.mean(scores_output) > np.mean(score) + 1:\n",
    "                cont = False\n",
    "        dist_tensor += 35*gen_tape.gradient(scores_output, dist_tensor)\n",
    "\n",
    "    # Store the new images\n",
    "    mae = 0\n",
    "    for j in range(25):\n",
    "        diff_im = dist_tensor.numpy()[j] - im[0][j]\n",
    "        mae += np.mean(np.abs(diff_im))\n",
    "        res = np.clip((im[0][j] + (10 * diff_im)) / 255.0, 0, 1)\n",
    "        plt.imsave(\"adversarial_ims/test{0}.png\".format(counter), res)\n",
    "        counter += 1\n",
    "    print(mae / 25.0)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
